\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage[margin=1in]{geometry}

% Theorem environments
\newtheorem{definition}{Definition}[section]
\newtheorem{property}{Property}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{remark}{Remark}[section]

% Custom commands
\newcommand{\statespace}{\mathcal{S}}
\newcommand{\actionspace}{\mathcal{A}}
\newcommand{\nodeset}{\mathcal{N}}
\newcommand{\tree}{\mathcal{T}}
\newcommand{\generator}{\mathcal{G}}
\newcommand{\evaluator}{\mathcal{E}}
\newcommand{\visits}{\nu}
\newcommand{\val}{v}
\newcommand{\ucb}{\text{UCB1}}

\title{MCTS-Reasoning: A Canonical Specification of\\Monte Carlo Tree Search for LLM Reasoning}
\author{Technical Report v0.5.1}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This technical report provides a rigorous specification of Monte Carlo Tree Search (MCTS) applied to Large Language Model (LLM) reasoning. We present formal definitions of the search tree structure, the four phases of MCTS (Selection, Expansion, Simulation, Backpropagation), and their adaptation for step-by-step reasoning with language models. Key design choices---including tree-building rollouts and terminal-only evaluation---are explicitly documented and justified. The goal is to establish a canonical reference specification that authentically captures the MCTS algorithm while adapting it for the unique characteristics of LLM-based reasoning tasks.
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{Introduction}
%==============================================================================

Monte Carlo Tree Search (MCTS) is a best-first search algorithm that uses random sampling to build a search tree and evaluate actions \cite{kocsis2006, coulom2006}. Originally developed for game playing---notably achieving superhuman performance in Go \cite{silver2016}---MCTS has proven effective in domains where the state space is too large for exhaustive search but where states can be evaluated through simulation.

In this report, we apply MCTS to \emph{reasoning} with Large Language Models. The key insight is that multi-step reasoning can be viewed as a sequential decision problem:
\begin{itemize}
    \item \textbf{States} are partial reasoning traces (text strings)
    \item \textbf{Actions} are reasoning continuations (next steps)
    \item \textbf{Terminal states} are complete solutions with answers
    \item \textbf{Rewards} are quality assessments of final answers
\end{itemize}

This formulation allows MCTS to systematically explore different reasoning paths, allocating more search effort to promising directions while maintaining exploration of alternatives. Recent work has explored similar ideas under the names ``Tree of Thoughts'' \cite{yao2023} and ``Reasoning via Planning'' \cite{hao2023}.

\subsection{Goals of This Specification}

\begin{enumerate}
    \item Provide \textbf{rigorous definitions} of all components
    \item Present the \textbf{MCTS algorithm} with precise pseudocode
    \item Specify the \textbf{adaptation to LLM reasoning} with clear interfaces
    \item Document \textbf{design choices} that distinguish this variant from classical MCTS
\end{enumerate}

\subsection{Scope and Assumptions}

This specification covers single-threaded MCTS for text-based reasoning. We assume:
\begin{itemize}
    \item The LLM produces valid text output for each query
    \item The Evaluator returns scores in $[0, 1]$
    \item State strings have bounded length (context window limits)
\end{itemize}

%==============================================================================
\section{Preliminaries}
%==============================================================================

\subsection{Notation}

We use the following notation throughout:
\begin{center}
\begin{tabular}{cl}
\toprule
Symbol & Meaning \\
\midrule
$\statespace$ & State space (set of all possible reasoning traces) \\
$\actionspace$ & Action space (set of all possible continuations) \\
$s \in \statespace$ & A state (partial or complete reasoning trace) \\
$a \in \actionspace$ & An action (reasoning continuation) \\
$\nodeset$ & Set of nodes in the search tree \\
$n \in \nodeset$ & A node in the search tree \\
$\visits(n)$ & Visit count of node $n$ \\
$\val(n)$ & Cumulative value of node $n$ \\
$c$ & Exploration constant in UCB1 \\
$B$ & Branching factor bound (max children per node) \\
$D$ & Maximum rollout depth \\
\bottomrule
\end{tabular}
\end{center}

%==============================================================================
\section{Formal Definitions}
%==============================================================================

\begin{definition}[State]
\label{def:state}
A \emph{state} $s \in \statespace$ is a string representing a partial or complete reasoning trace. A state consists of the concatenation of:
\begin{enumerate}
    \item The original question
    \item Zero or more reasoning steps
    \item Optionally, a terminal marker with a final answer
\end{enumerate}
\end{definition}

\begin{definition}[Terminal State]
\label{def:terminal}
A state $s$ is \emph{terminal} if a \emph{terminal detector} determines it contains a complete answer. Formally:
\[
\textsc{IsTerminal}(s) = \textsc{TerminalDetector}.\textsc{Check}(s)
\]
The detector also extracts the answer: $\textsc{ExtractAnswer}(s) \rightarrow \text{Answer} \cup \{\bot\}$.
\end{definition}

\begin{definition}[Terminal Detector]
\label{def:terminaldetector}
A \emph{terminal detector} is a component that determines when reasoning is complete:
\begin{itemize}
    \item $\textsc{Check}(s) \rightarrow \{\texttt{true}, \texttt{false}\}$: determines if $s$ is terminal
    \item $\textsc{ExtractAnswer}(s) \rightarrow \text{Answer}$: extracts the answer from terminal $s$
    \item $\textsc{FormatInstruction}() \rightarrow \text{String}$: provides prompt guidance for the LLM
\end{itemize}
\end{definition}

\begin{remark}[Terminal Detector Implementations]
The canonical implementation uses a \emph{marker-based detector} that looks for the string ``\texttt{ANSWER:}''. Alternative implementations include:
\begin{itemize}
    \item \textbf{BoxedDetector}: Looks for \LaTeX-style $\backslash$\texttt{boxed\{...\}} (common in math benchmarks)
    \item \textbf{MultiMarkerDetector}: Accepts multiple completion signals
    \item \textbf{LLM-as-Judge}: Asks an LLM whether reasoning is complete (more expensive)
\end{itemize}
The terminal detector's \textsc{FormatInstruction} is included in prompts so the LLM knows the expected answer format.
\end{remark}

\begin{definition}[Action]
\label{def:action}
An \emph{action} $a$ is an operation that transforms a state into a new state. Formally:
\[
a: \statespace \rightarrow \statespace
\]
The canonical action is \textsc{Continue}, which prompts the LLM to generate the next reasoning step:
\[
\textsc{Continue}(s) = s \oplus \generator(s)
\]
where $\oplus$ denotes string concatenation with appropriate formatting.
\end{definition}

\begin{definition}[Action Space]
\label{def:actionspace}
The \emph{action space} $\actionspace(s)$ is the set of actions available at state $s$:
\[
\actionspace(s) = \begin{cases}
\emptyset & \text{if } \textsc{IsTerminal}(s) \\
\{\textsc{Continue}\} & \text{otherwise (canonical case)}
\end{cases}
\]
\end{definition}

\begin{remark}[State-Dependent Actions]
In standard MCTS for games, different positions have different legal moves. Similarly, different reasoning states may have different available actions. The canonical implementation uses only \textsc{Continue}, but extensions (Section~\ref{sec:extensions}) may include additional actions such as \textsc{Compress} for long traces.
\end{remark}

\begin{definition}[Node]
\label{def:node}
A \emph{node} $n$ in the search tree consists of:
\begin{itemize}
    \item $\text{state}(n) \in \statespace$: the reasoning trace at this node
    \item $\visits(n) \in \mathbb{N}_0$: the number of times this node has been visited
    \item $\val(n) \in \mathbb{R}_{\geq 0}$: the cumulative value from simulations through this node
    \item $\text{children}(n) \subseteq \nodeset$: the set of child nodes
    \item $\text{parent}(n) \in \nodeset \cup \{\bot\}$: the parent node (or $\bot$ for root)
    \item $\text{terminal}(n) \in \{\texttt{true}, \texttt{false}\}$: whether this is a terminal state
    \item $\text{answer}(n)$: the extracted answer (if terminal)
\end{itemize}
\end{definition}

\begin{definition}[Search Tree]
\label{def:tree}
A \emph{search tree} $\tree = (\nodeset, E, r)$ is a rooted tree where:
\begin{itemize}
    \item $\nodeset$ is the set of nodes
    \item $E = \{(\text{parent}(n), n) : n \in \nodeset, \text{parent}(n) \neq \bot\}$ is the edge set
    \item $r \in \nodeset$ is the root node with $\text{parent}(r) = \bot$
\end{itemize}
The tree is an arborescence: every node except the root has exactly one parent, and there is a unique path from $r$ to any node.
\end{definition}

\begin{definition}[Average Value]
\label{def:avgvalue}
The \emph{average value} of a node $n$ with $\visits(n) > 0$ is:
\[
\bar{\val}(n) = \frac{\val(n)}{\visits(n)}
\]
For $\visits(n) = 0$, the average value is undefined.
\end{definition}

\begin{definition}[Branching Factor Bound]
\label{def:branching}
The \emph{branching factor bound} $B \in \mathbb{N}$ is the maximum number of children any node may have. A node $n$ is \emph{fully expanded} if and only if:
\[
\textsc{FullyExpanded}(n) = \big(|\text{children}(n)| \geq B\big) \lor \textsc{IsTerminal}(\text{state}(n))
\]
\end{definition}

%==============================================================================
\section{The MCTS Algorithm}
%==============================================================================

MCTS builds a search tree incrementally through repeated \emph{simulations}. Each simulation consists of four phases: Selection, Expansion, Rollout, and Backpropagation.

\begin{algorithm}[H]
\caption{MCTS Main Loop}
\label{alg:mcts-main}
\begin{algorithmic}[1]
\Require Question $q$, number of simulations $K$, branching factor $B$, max depth $D$
\Ensure Search tree with root $r$
\Procedure{Search}{$q, K, B, D$}
    \State $r \gets \textsc{CreateNode}(q)$ \Comment{Root state is the question}
    \For{$i = 1$ \textbf{to} $K$}
        \State $n_{\text{leaf}} \gets \textsc{Select}(r)$
        \State $n_{\text{exp}} \gets \textsc{Expand}(n_{\text{leaf}}, B)$
        \State $n_{\text{term}}, \val \gets \textsc{Rollout}(n_{\text{exp}}, D)$
        \State \textsc{Backpropagate}($n_{\text{term}}, \val$)
    \EndFor
    \State \Return $r$
\EndProcedure
\end{algorithmic}
\end{algorithm}

%------------------------------------------------------------------------------
\subsection{Phase 1: Selection}
%------------------------------------------------------------------------------

Selection traverses the tree from root to a leaf, choosing children according to the UCB1 policy.

\begin{definition}[UCB1]
\label{def:ucb1}
For a non-root node $n$ with parent $p = \text{parent}(n)$, the \emph{Upper Confidence Bound} is:
\[
\ucb(n) = \begin{cases}
+\infty & \text{if } \visits(n) = 0 \\[6pt]
\displaystyle \bar{\val}(n) + c \sqrt{\frac{\ln \visits(p)}{\visits(n)}} & \text{if } \visits(n) > 0
\end{cases}
\]
where $c > 0$ is the exploration constant. The first term $\bar{\val}(n)$ is the \emph{exploitation} component; the second term is the \emph{exploration} component.
\end{definition}

\begin{remark}[Exploration Constant]
The theoretical value $c = \sqrt{2}$ derives from the UCB1 bandit algorithm \cite{kocsis2006}. In practice, $c$ may be tuned: larger values encourage exploration, smaller values favor exploitation.
\end{remark}

\begin{remark}[Tie-Breaking]
When multiple children have equal UCB1 values (including multiple unvisited children with $\ucb = +\infty$), we select uniformly at random among them.
\end{remark}

\begin{algorithm}[H]
\caption{Selection Phase}
\label{alg:selection}
\begin{algorithmic}[1]
\Require Node $n$ (typically root)
\Ensure Leaf node for expansion
\Procedure{Select}{$n$}
    \While{$\textsc{FullyExpanded}(n)$ \textbf{and} $\text{children}(n) \neq \emptyset$}
        \State $n \gets \arg\max_{c \in \text{children}(n)} \ucb(c)$ \Comment{Break ties randomly}
    \EndWhile
    \State \Return $n$
\EndProcedure
\end{algorithmic}
\end{algorithm}

%------------------------------------------------------------------------------
\subsection{Phase 2: Expansion}
%------------------------------------------------------------------------------

Expansion adds a new child node by generating a continuation from the Generator.

\begin{algorithm}[H]
\caption{Expansion Phase}
\label{alg:expansion}
\begin{algorithmic}[1]
\Require Node $n$, branching factor bound $B$
\Ensure Expanded node (new child or $n$ if unexpandable)
\Procedure{Expand}{$n, B$}
    \If{$\textsc{IsTerminal}(\text{state}(n))$}
        \State \Return $n$ \Comment{Cannot expand terminal nodes}
    \EndIf
    \If{$|\text{children}(n)| \geq B$}
        \State \Return $n$ \Comment{Fully expanded}
    \EndIf
    \State $a \gets \generator.\textsc{Generate}(\text{state}(n))$ \Comment{Get one continuation}
    \State $s' \gets \text{state}(n) \oplus a$
    \State $n' \gets \textsc{CreateNode}(s')$
    \State $\text{parent}(n') \gets n$
    \State $\text{children}(n) \gets \text{children}(n) \cup \{n'\}$
    \State \Return $n'$
\EndProcedure
\end{algorithmic}
\end{algorithm}

%------------------------------------------------------------------------------
\subsection{Phase 3: Rollout (Simulation)}
%------------------------------------------------------------------------------

The rollout phase continues from the expanded node until reaching a terminal state or the maximum depth.

\begin{remark}[Design Choice: Tree-Building Rollout]
\label{rem:tree-building}
In classical MCTS for games, rollouts typically use a fast, random policy \emph{without} adding nodes to the tree. However, for LLM reasoning, we make a deliberate design choice to \textbf{add rollout nodes to the tree}. This preserves the full reasoning trace and allows:
\begin{enumerate}
    \item Reuse of reasoning steps in future simulations
    \item Inspection of the complete reasoning path
    \item Consistent state representation throughout the tree
\end{enumerate}
This is sometimes called ``tree policy all the way'' or ``persistent tree'' MCTS.
\end{remark}

\begin{algorithm}[H]
\caption{Rollout Phase (Tree-Building)}
\label{alg:rollout}
\begin{algorithmic}[1]
\Require Node $n$, maximum depth $D$
\Ensure Terminal node $n_{\text{term}}$ and its value $\val$
\Procedure{Rollout}{$n, D$}
    \State $\text{current} \gets n$
    \State $\text{depth} \gets 0$
    \While{$\neg\textsc{IsTerminal}(\text{state}(\text{current}))$ \textbf{and} $\text{depth} < D$}
        \State $a \gets \generator.\textsc{Generate}(\text{state}(\text{current}))$
        \State $s' \gets \text{state}(\text{current}) \oplus a$
        \State $n' \gets \textsc{CreateNode}(s')$
        \State $\text{parent}(n') \gets \text{current}$
        \State $\text{children}(\text{current}) \gets \text{children}(\text{current}) \cup \{n'\}$
        \State $\text{current} \gets n'$
        \State $\text{depth} \gets \text{depth} + 1$
    \EndWhile
    \If{$\textsc{IsTerminal}(\text{state}(\text{current}))$}
        \State $\val \gets \evaluator.\textsc{Evaluate}(\text{state}(\text{current}), \text{answer}(\text{current}))$
    \Else
        \State $\val \gets 0$ \Comment{No terminal reached within depth limit}
    \EndIf
    \State \Return $(\text{current}, \val)$
\EndProcedure
\end{algorithmic}
\end{algorithm}

%------------------------------------------------------------------------------
\subsection{Phase 4: Backpropagation}
%------------------------------------------------------------------------------

Backpropagation updates visit counts and values along the path from the terminal node to the root.

\begin{algorithm}[H]
\caption{Backpropagation Phase}
\label{alg:backprop}
\begin{algorithmic}[1]
\Require Terminal node $n_{\text{term}}$, value $\val$
\Procedure{Backpropagate}{$n_{\text{term}}, \val$}
    \State $n \gets n_{\text{term}}$
    \While{$n \neq \bot$}
        \State $\visits(n) \gets \visits(n) + 1$
        \State $\val(n) \gets \val(n) + \val$
        \State $n \gets \text{parent}(n)$
    \EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{property}[Visit Count Invariant]
\label{prop:visits}
For any node $n$ in the tree:
\[
\visits(n) = \sum_{c \in \text{children}(n)} \visits(c) + \mathbb{1}[n \text{ is a rollout endpoint}]
\]
where $\mathbb{1}[\cdot]$ is the indicator function. In particular, $\visits(\text{root}) = K$ after $K$ simulations.
\end{property}

%==============================================================================
\section{Application to LLM Reasoning}
%==============================================================================

The MCTS algorithm requires two external components: a \emph{Generator} to produce continuations and an \emph{Evaluator} to score terminal states.

%------------------------------------------------------------------------------
\subsection{Generator}
%------------------------------------------------------------------------------

\begin{definition}[Generator]
\label{def:generator}
A \emph{Generator} $\generator$ is a function that produces reasoning continuations:
\[
\generator: \statespace \rightarrow \actionspace
\]
Given a state $s$, it returns a continuation $a$. The continuation may result in a terminal state (if it contains the answer marker) or a non-terminal state (requiring further reasoning).
\end{definition}

For LLM-based generation, we use the following procedure:

\begin{algorithm}[H]
\caption{LLM Generator}
\label{alg:llm-generator}
\begin{algorithmic}[1]
\Require State $s$, temperature $\tau$
\Ensure Continuation $a$
\Procedure{Generate}{$s$}
    \State $\text{prompt} \gets \textsc{FormatPrompt}(s)$
    \State $\text{response} \gets \text{LLM}(\text{prompt}, \text{temperature}=\tau)$
    \State $a \gets \textsc{ParseContinuation}(\text{response})$
    \State \Return $a$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{definition}[Prompt Template]
\label{def:prompt}
The prompt template formats the current state for the LLM:
\begin{verbatim}
You are solving a problem step by step.
Current reasoning:
{state}

Continue with the next step. When you reach a final answer,
write "ANSWER: " followed by your answer.

Next step:
\end{verbatim}
The temperature $\tau > 0$ controls diversity: higher temperatures yield more varied continuations.
\end{definition}

%------------------------------------------------------------------------------
\subsection{Evaluator}
%------------------------------------------------------------------------------

\begin{definition}[Evaluator]
\label{def:evaluator}
An \emph{Evaluator} $\evaluator$ is a function that scores terminal states:
\[
\evaluator: \statespace \times \text{Answer} \rightarrow [0, 1]
\]
Given a terminal state and its extracted answer, it returns a quality score.
\end{definition}

\begin{remark}[Terminal-Only Evaluation]
The Evaluator is invoked \emph{only} on terminal states. This design choice reduces computational cost: intermediate reasoning states are not evaluated, and LLM-as-judge calls occur only when a complete answer is produced.
\end{remark}

\begin{algorithm}[H]
\caption{LLM Evaluator (LLM-as-Judge)}
\label{alg:llm-evaluator}
\begin{algorithmic}[1]
\Require Terminal state $s$, extracted answer $a$
\Ensure Score $\in [0, 1]$
\Procedure{Evaluate}{$s, a$}
    \State $\text{prompt} \gets \textsc{FormatJudgePrompt}(s, a)$
    \State $\text{response} \gets \text{LLM}(\text{prompt}, \text{temperature}=0)$
    \State $\text{score} \gets \textsc{ParseScore}(\text{response})$
    \State \Return $\text{score}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\textbf{Alternative Evaluators:}
\begin{itemize}
    \item \textbf{Ground Truth}: Compare answer to known correct answer with normalization (lowercase, strip punctuation). Supports partial credit when answer contains the truth or vice versa.

    \item \textbf{Numeric}: For mathematical problems, compares numeric values with configurable tolerance (absolute and relative). Extracts numbers from text, handles fractions (e.g., ``1/2''), scientific notation, and provides partial credit based on relative error.

    \item \textbf{Process}: Evaluates reasoning quality using heuristics---presence of step-by-step structure, mathematical notation, verification statements, and logical connectives. Can be combined with an answer evaluator via weighted sum.

    \item \textbf{Composite}: Weighted combination of multiple evaluators. For example: $0.7 \times \text{NumericScore} + 0.3 \times \text{ProcessScore}$.

    \item \textbf{Self-Consistency}: Score based on agreement with other sampled solutions (not implemented in canonical version).
\end{itemize}

%==============================================================================
\section{Result Extraction}
%==============================================================================

After search completes, we extract the best answer from the tree.

\begin{algorithm}[H]
\caption{Best Answer Extraction}
\label{alg:best-answer}
\begin{algorithmic}[1]
\Require Root node $r$
\Ensure Best answer and confidence score
\Procedure{GetBestAnswer}{$r$}
    \State $n \gets r$
    \While{$\text{children}(n) \neq \emptyset$}
        \State $n \gets \arg\max_{c \in \text{children}(n)} \visits(c)$ \Comment{Most-visited child}
    \EndWhile
    \If{$\textsc{IsTerminal}(\text{state}(n))$}
        \State \Return $(\text{answer}(n), \bar{\val}(n))$
    \Else
        \State \Return $(\texttt{null}, 0)$
    \EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{remark}
Following most-visited children (rather than highest-value) is standard practice in MCTS, as visit counts are more robust to value noise than raw averages.
\end{remark}

%==============================================================================
\section{Complexity Analysis}
%==============================================================================

\begin{property}[Time Complexity]
For $K$ simulations with maximum depth $D$:
\begin{itemize}
    \item \textbf{Selection}: $O(D)$ node traversals per simulation
    \item \textbf{Expansion}: $O(1)$ plus one Generator call
    \item \textbf{Rollout}: $O(D)$ Generator calls (worst case)
    \item \textbf{Backpropagation}: $O(D)$ node updates
\end{itemize}
Total tree operations: $O(KD)$. The dominant cost is typically LLM calls: up to $O(KD)$ Generator calls and $O(K)$ Evaluator calls.
\end{property}

\begin{property}[Space Complexity]
The search tree contains at most $O(KD)$ nodes, each storing a state string. With bounded state length $L$, space complexity is $O(KDL)$.
\end{property}

%==============================================================================
\section{Extensions}
\label{sec:extensions}
%==============================================================================

The following extensions are under consideration for future versions:

\subsection{Extended Action Spaces}

The canonical implementation uses only the \textsc{Continue} action. Extended action spaces may include:

\begin{itemize}
    \item \textbf{Compress}: When the reasoning trace exceeds a threshold length, the \textsc{Compress} action summarizes the trace into a more compact representation. Subsequent reasoning continues from the compressed state, reducing context length while preserving key insights.
    \[
    \actionspace(s) = \begin{cases}
        \{\textsc{Continue}, \textsc{Compress}\} & \text{if } |s| > \text{threshold} \\
        \{\textsc{Continue}\} & \text{otherwise}
    \end{cases}
    \]

    \item \textbf{Verify}: Ask the LLM to verify the current reasoning before continuing

    \item \textbf{ToolCall}: Invoke external tools via Model Context Protocol (MCP).
          \emph{Implemented in v0.5 via \texttt{ToolAwareGenerator} and \texttt{ToolContext}.}

    \item \textbf{Backtrack}: Explicitly mark a reasoning path as unpromising
\end{itemize}

\subsection{Algorithm Variants}

\begin{itemize}
    \item \textbf{Progressive Widening}: Dynamically adjust $B$ based on visit count
    \item \textbf{RAVE}: Rapid Action Value Estimation for faster convergence
    \item \textbf{Parallel MCTS}: Root parallelization or tree parallelization
    \item \textbf{Value Networks}: Learned evaluation functions for intermediate states
    \item \textbf{Policy Networks}: Learned action selection to guide expansion
    \item \textbf{Self-Consistency Integration}: Aggregate across multiple terminal states
    \item \textbf{Beam Search Hybrid}: Combine MCTS exploration with beam search
\end{itemize}

\subsection{Beyond Trees: Graph-Based Reasoning}

The tree structure of MCTS imposes fundamental constraints on reasoning patterns. Certain operations naturally suggest non-tree structures:

\begin{itemize}
    \item \textbf{Problem Decomposition}: Splitting a problem into independent subproblems, solving each separately, and combining results creates a DAG structure where the ``combine'' node has multiple parents.

    \item \textbf{Critique-Revision Cycles}: Evaluating a solution, identifying issues, and refining creates potential cycles that trees cannot represent.

    \item \textbf{Cross-Path Information Sharing}: Using insights from one reasoning path to inform another requires edges between branches.
\end{itemize}

These patterns require \emph{graph-based} or \emph{hypergraph-based} search with:
\begin{itemize}
    \item Multiple edge types (continuation, decomposition, aggregation, critique)
    \item Generalized propagation beyond simple backpropagation
    \item Synchronization semantics for subproblem completion
\end{itemize}

Such extensions are outside the scope of this tree-based MCTS specification but represent promising directions for future work on structured reasoning.

\begin{remark}[Natural Decomposition within MCTS]
Note that the LLM within a \textsc{Continue} action can naturally perform soft versions of these operations: reasoning about subproblems sequentially within a single path, self-critiquing before continuing, or reconsidering earlier steps. The tree structure captures \emph{alternative} reasoning paths, while complex reasoning \emph{within} a path remains expressible through the continuation mechanism.
\end{remark}

%------------------------------------------------------------------------------
\subsection{MCP Tool Integration (Implemented)}
\label{subsec:mcp-tools}
%------------------------------------------------------------------------------

Version 0.5 introduces tool-augmented reasoning via the Model Context Protocol (MCP):

\begin{itemize}
    \item \textbf{ToolAwareGenerator}: Wraps any Generator with tool support, intercepting tool calls in LLM output and executing them before continuing generation.
    \item \textbf{ToolContext}: Manages MCP server connections, tool discovery, and execution. Provides a unified interface for tool invocation.
    \item \textbf{Native Function Calling}: Direct API integration for OpenAI and Anthropic providers, using their native tool-use APIs for improved reliability.
    \item \textbf{RAG Server}: Built-in MCP server for retrieval-augmented guidance, exposing tools for retrieving similar examples and domain-specific guidance.
\end{itemize}

Tools are invoked during reasoning steps via XML or JSON format:
\begin{verbatim}
<tool_call name="calculator">
  <expression>15 * 7 + 23</expression>
</tool_call>
\end{verbatim}
Results are injected back into the state, allowing the LLM to continue reasoning with tool outputs.

%------------------------------------------------------------------------------
\subsection{Sampling and Self-Consistency (Implemented)}
\label{subsec:sampling}
%------------------------------------------------------------------------------

Beyond extracting the single best answer, version 0.5 provides path sampling strategies for analyzing the search tree:

\begin{itemize}
    \item \textbf{Value-based}: Sample paths with highest average values
    \item \textbf{Visit-based}: Sample most frequently visited paths (robust to noise)
    \item \textbf{Diverse}: Maximize answer diversity across samples
    \item \textbf{Top-$k$}: Sample $k$ best paths by specified criterion
\end{itemize}

Self-consistency voting aggregates across multiple terminal states to improve answer reliability:
\begin{itemize}
    \item \textbf{Majority vote}: $\arg\max_a |\{p : \text{answer}(p) = a\}|$ --- simple count of each answer
    \item \textbf{Weighted vote}: $\arg\max_a \sum_{p : \text{answer}(p) = a} \bar{\val}(p)$ --- answers weighted by path values
\end{itemize}

The \texttt{PathSampler} class provides these operations:
\begin{verbatim}
sampler = PathSampler(result.root)
paths = sampler.sample(n=5, strategy="diverse")
answer, confidence = sampler.majority_vote()
\end{verbatim}

%------------------------------------------------------------------------------
\subsection{Tree Serialization (Implemented)}
\label{subsec:serialization}
%------------------------------------------------------------------------------

Search trees can be serialized to JSON and resumed, enabling:
\begin{itemize}
    \item Incremental search (add more simulations to existing tree)
    \item Tree inspection and debugging
    \item Checkpointing long-running searches
    \item Sharing trees between sessions
\end{itemize}

The operations are:
\begin{itemize}
    \item $\textsc{Save}(\tree, \text{path})$: Serialize tree structure, visit counts, values, and terminal states to JSON
    \item $\textsc{Load}(\text{path}, \generator, \evaluator) \rightarrow \tree$: Restore tree from file, reconnecting to new Generator/Evaluator instances
    \item $\textsc{ContinueSearch}(K)$: Add $K$ more simulations to the loaded tree
\end{itemize}

Example usage:
\begin{verbatim}
# Save after initial search
result = mcts.search("What is 2+2?", simulations=50)
mcts.save("tree.json")

# Later: load and continue
mcts = MCTS.load("tree.json", generator, evaluator)
result = mcts.continue_search(simulations=50)  # Now 100 total
\end{verbatim}

%==============================================================================
\section{Conclusion}
%==============================================================================

This report establishes a canonical specification for MCTS applied to LLM reasoning. The key contributions are:

\begin{enumerate}
    \item \textbf{Rigorous formal definitions} of states, actions, nodes, and the search tree
    \item \textbf{Precise specification} of the four MCTS phases with pseudocode
    \item \textbf{Clear interfaces} for Generator and Evaluator components
    \item \textbf{Explicit documentation} of design choices (tree-building rollouts, terminal-only evaluation, bounded branching)
\end{enumerate}

The specification serves as a reference for implementation, ensuring the algorithm is authentically represented while being appropriately adapted for language model reasoning tasks.

%==============================================================================
% References
%==============================================================================
\bibliographystyle{plain}
\begin{thebibliography}{9}

\bibitem{kocsis2006}
Kocsis, L., \& Szepesv{\'a}ri, C. (2006).
Bandit based monte-carlo planning.
\textit{European Conference on Machine Learning}, 282--293.

\bibitem{coulom2006}
Coulom, R. (2006).
Efficient selectivity and backup operators in monte-carlo tree search.
\textit{International Conference on Computers and Games}, 72--83.

\bibitem{browne2012}
Browne, C. B., et al. (2012).
A survey of monte carlo tree search methods.
\textit{IEEE Transactions on Computational Intelligence and AI in Games}, 4(1), 1--43.

\bibitem{silver2016}
Silver, D., et al. (2016).
Mastering the game of Go with deep neural networks and tree search.
\textit{Nature}, 529(7587), 484--489.

\bibitem{yao2023}
Yao, S., et al. (2023).
Tree of thoughts: Deliberate problem solving with large language models.
\textit{arXiv preprint arXiv:2305.10601}.

\bibitem{hao2023}
Hao, S., et al. (2023).
Reasoning with language model is planning with world model.
\textit{arXiv preprint arXiv:2305.14992}.

\end{thebibliography}

%==============================================================================
\appendix
\section{Implementation Notes}
\label{app:implementation}
%==============================================================================

This appendix provides practical implementation details for the canonical MCTS-Reasoning system.

\subsection{State Lifecycle}

States are accumulated text strings. The transition from initial to terminal state follows this pattern:

\begin{verbatim}
Initial State (root):
  "Question: What is 15*7+23?
   Let me solve this step by step."
          |
    [CONTINUE action]
          v
Child State:
  "Question: What is 15*7+23?
   Let me solve this step by step.
   Step 1: First, calculate 15*7 = 105"
          |
    [CONTINUE action]
          v
Terminal State:
  "Question: What is 15*7+23?
   ...
   Step 2: Then add 23: 105 + 23 = 128
   ANSWER: 128"
\end{verbatim}

\textbf{Key Properties:}
\begin{center}
\begin{tabular}{lll}
\toprule
Property & Status & Notes \\
\midrule
Well-defined & Yes & Strings with clear semantics \\
Markov & Yes & Generator sees only current state \\
Traceable & Yes & Parent pointers reconstruct full path \\
Bounded & No & States grow unboundedly (limitation) \\
\bottomrule
\end{tabular}
\end{center}

\subsection{UCB1 Visualization}

The UCB1 formula balances exploration and exploitation:

\begin{verbatim}
UCB1 = average_value + c * sqrt(ln(parent_visits) / visits)
       -------------   ------------------------------------
       EXPLOITATION              EXPLORATION
\end{verbatim}

\begin{itemize}
    \item Unvisited nodes have UCB1 $= +\infty$ (highest priority)
    \item High-value, low-visit nodes are attractive (explore more)
    \item High-value, high-visit nodes are reliable (exploit)
    \item Low-value nodes are deprioritized regardless of visits
\end{itemize}

Default exploration constant: $c = \sqrt{2} \approx 1.414$. Higher values encourage exploration; lower values favor exploitation.

\subsection{Evaluator Comparison}

\begin{center}
\begin{tabular}{lll}
\toprule
Evaluator & Scoring Method & Best For \\
\midrule
NumericEvaluator & Compare to ground truth with tolerance & Math problems \\
GroundTruthEvaluator & Exact/partial string match & Known answers \\
ProcessEvaluator & Heuristic scoring of reasoning quality & Open-ended \\
LLMEvaluator & LLM-as-judge (0--1 score) & Subjective quality \\
CompositeEvaluator & Weighted combination & Multiple criteria \\
\bottomrule
\end{tabular}
\end{center}

\textbf{NumericEvaluator Scoring:}
\begin{itemize}
    \item Exact match (within tolerance): 1.0
    \item Within 10\% relative error: 0.8
    \item Within 50\% relative error: 0.5
    \item Beyond 50\% error: 0.0
\end{itemize}

\subsection{Code Location Reference}

Primary implementation files in the \texttt{mcts\_reasoning/} package:

\begin{center}
\begin{tabular}{ll}
\toprule
Component & File \\
\midrule
Node (UCB1, tree structure) & \texttt{node.py} \\
MCTS (search algorithm) & \texttt{mcts.py} \\
Generator (LLM continuation) & \texttt{generator.py} \\
Evaluator (terminal scoring) & \texttt{evaluator.py} \\
Terminal detection & \texttt{terminal.py} \\
Actions (Continue, Compress) & \texttt{actions.py} \\
Path sampling & \texttt{sampling.py} \\
MCP tool integration & \texttt{tools/} \\
LLM providers & \texttt{compositional/providers.py} \\
RAG stores & \texttt{compositional/rag.py} \\
\bottomrule
\end{tabular}
\end{center}

\subsection{Debugging Tips}

\textbf{No Terminal States Found:}
\begin{itemize}
    \item Increase \texttt{max\_rollout\_depth}
    \item Check terminal detector configuration
    \item Verify LLM generates ``ANSWER:'' markers
\end{itemize}

\textbf{Low Confidence:}
\begin{itemize}
    \item Increase simulation count
    \item Use ProcessEvaluator for reasoning quality assessment
    \item Check answer consistency with \texttt{PathSampler.consistency\_score()}
\end{itemize}

\textbf{LLM Provider Issues:}
\begin{itemize}
    \item Ollama: Test with \texttt{curl http://localhost:11434/api/tags}
    \item Check API keys in environment variables
    \item Use \texttt{MockLLMProvider} for isolated testing
\end{itemize}

\end{document}
